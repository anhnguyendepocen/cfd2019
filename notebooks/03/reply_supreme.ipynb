{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Our task](../02/sampling_problem) has been to reply to the Supreme Court on\n",
    "their judgment in the appeal of Robert Swain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, Robert Swain appealed his death sentence, for rape, on the\n",
    "basis that the jury selection was biased against black people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "His trial had a jury pool, of 100, from which the jury had to be selected.\n",
    "That jury pool should have been representative of the local population.\n",
    "\n",
    "The jury pool had 8 black people, but the local population was 26% black.\n",
    "\n",
    "If the jury pool had been representative, we would expect about 26 of 100\n",
    "people to be black.  Our question is what we mean by *about* 26 of 100.\n",
    "\n",
    "The Supreme Court thought that the difference between expected (26) and actual\n",
    "(8) was small. But was it?  Does 8 of 100 fit somewhere in our description of\n",
    "*about* 26 of 100?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this, we are going to *simulate* making a jury pool.\n",
    "\n",
    "Our *model* is that each juror has been randomly selected from the population.\n",
    "That is, for any one juror, there is a 0.26 probability that they are black.\n",
    "\n",
    "First we make one jury pool, of 100, to remind ourselves of the task.\n",
    "\n",
    "Then we make 10 jury pools of 100, to get warmed up.\n",
    "\n",
    "Finally we make 10000 jury pools, each of 100 members, and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the array library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is one jury pool, and the number of black people we get in our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make 100 random integers from 0 through 99\n",
    "randoms = np.random.randint(0, 100, size=100)\n",
    "# Say values < 26 correspond to black jurors.\n",
    "black_yn = randoms < 0.26\n",
    "# We now have True for black jurors and False otherwise.\n",
    "# Count the number of Trues\n",
    "np.count_nonzero(black_yn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is one estimate, for the number of black people we can expect, if our\n",
    "model is correct.  Call this one *trial*. We can run that a few times to get a\n",
    "range of values.   If we run it only a few times, we might be unlucky, and get\n",
    "some results that are not representative.  It is safer to run it a huge number\n",
    "of times, to make sure we've got an idea of the variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we get ready to store the results of each estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty counts array, to append to.\n",
    "counts = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the code from the cell above, but now, we append to the `counts` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randoms = np.random.randint(0, 100, size=100)\n",
    "black_yn = randoms < 0.26\n",
    "count = np.count_nonzero(black_yn)\n",
    "counts = np.append(counts, count)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell above a few times, perhaps with Control-Enter, to see the `counts` array extending, for each time we run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we collect the result of many trials, by using a for loop.\n",
    "\n",
    "We will start by making 10 jury pools, to get warmed up.  Later we will use\n",
    "a much higher number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 2., 3., 0., 1., 0., 1., 0., 2., 2., 1., 0., 1., 1., 1.,\n",
       "       0., 2., 0., 2., 1., 1., 1., 2., 2., 2., 0., 0., 1., 1., 2., 7., 0.,\n",
       "       0., 1., 3., 4., 2., 0., 1., 1., 2., 2., 0., 0., 2., 0., 2., 3., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 2., 0., 0., 2., 0., 0., 2., 2., 0., 1.,\n",
       "       0., 2., 1., 0., 0., 2., 0., 1., 1., 0., 3., 3., 2., 1., 2., 2., 1.,\n",
       "       0., 1., 2., 2., 2., 0., 1., 0., 1., 0., 0., 2., 2., 0., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a new empty counts array, to append to.\n",
    "counts = np.array([])\n",
    "for i in np.arange(100):\n",
    "    # This code is the same as the cell above, but indented,\n",
    "    # so we run it all, for each time through the for loop.\n",
    "    randoms = np.random.randint(0, 100, size=100)\n",
    "    black_yn = randoms < 0.26\n",
    "    count = np.count_nonzero(black_yn)\n",
    "    counts = np.append(counts, count)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these values is one estimate for how many black jurors we should\n",
    "expect, if our model is right.  Already we get the feeling that 8 is rather\n",
    "unlikely, if our model is correct.  But - how unlikely?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better estimate, let us do the same thing, but with 10000 jury pools,\n",
    "and therefore, 10000 estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 1., ..., 4., 1., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a new empty counts array, to append to.\n",
    "counts = np.array([])\n",
    "for i in np.arange(10000):\n",
    "    # This code is the same as the cell above, but indented,\n",
    "    # so we run it all, for each time through the for loop.\n",
    "    randoms = np.random.randint(0, 100, size=100)\n",
    "    black_yn = randoms < 0.26\n",
    "    count = np.count_nonzero(black_yn)\n",
    "    counts = np.append(counts, count)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran this cell yourself, you will notice that it runs very fast, in much\n",
    "less than a second, on a reasonable laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 10000 estimates, one for each row in the original array, and\n",
    "therefore, one for each simulated jury pool.\n",
    "\n",
    "Remember, the function `len` shows us the length of the array, and therefore,\n",
    "the number of values in this one-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to have a look at the spread of these values.  To do this, we plot\n",
    "a histogram.  Here is how to do that, in Python.  Don't worry about the details, we will go into this more soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't worry about this bit of code for now.\n",
    "# It sets up plotting in the notebook.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Fancy plots\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now show the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3604., 3735.,    0., 1870.,    0.,  606.,  147.,    0.,   34.,\n",
       "           4.]),\n",
       " array([0. , 0.6, 1.2, 1.8, 2.4, 3. , 3.6, 4.2, 4.8, 5.4, 6. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do the histogram of our 10000 estimates.\n",
    "plt.hist(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as if 8 is nowhere on the spread of our estimates.  How many times did\n",
    "we get a value less than or equal to 8, in all our 10000 estimates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_are_low = counts <= 8\n",
    "np.count_nonzero(counts_are_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 10000 random jury pools, we never see a value as low as 8.  We can ask Numpy\n",
    "to show us the minimum value that we do see, by using the `np.min` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have run an analysis assuming that the jurors were selected at random.  On\n",
    "that assumption, a count of 8 jurors in 1000 is incredibly unlikely.  It is so\n",
    "unlikely, that we never get a number as low as 8, in 10000 repeats.   That\n",
    "makes us think that the probability of getting 8 black people in a jury pool of\n",
    "100, is less than 1 in 10000 or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 10000"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown",
    "format_version": "1.0",
    "jupytext_version": "0.8.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
