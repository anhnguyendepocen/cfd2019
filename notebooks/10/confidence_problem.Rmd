---
jupyter:
  jupytext:
    split_at_heading: true
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

Imagine for a moment that you are the person who supervises recruitment for the
New York City police department.

Anyone who wants to be a police officer in New York City, has take a [written
exam](https://www1.nyc.gov/site/nypd/careers/police-officers/po-exam.page). The
city puts on this exam every year or so.

There was a written exam in early 2017; over 10000 people took this exam.

Now it is 2019.   This new iteration of the written exam has just finished, and
you know that about 13000 people took the exam, but the results are not out
yet.  Of course you do have the results from 2017.

You are particularly interested in this year's results, because you are worried
that candidates are starting to find the exam too easy, especially with all the
exam preparation materials that candidates can find and buy.

In order to plan for the year ahead, you need to know if the results are
holding steady.   But, as things stand, you won't get the full results for 2019
for another month.

To help your decision-making, you very much want to get an idea of how good the
results are this year.   Being wise, you decided to take a random sample of 50
from all the exam papers from this year (2019).  You get them marked quickly.
But - how much information will this sample give you about the eventual results
for 2019?

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
plt.style.use('fivethirtyeight')
```

Here are the
[actual](https://github.com/matthew-brett/datasets/tree/22203c1/nyc_civil_list)
examination results from the big 2017 police written exam.


You can download the file from [nyc_police_exam_sept_2017.csv]({{ site.baseurl
}}/data/nyc_police_exam_sept_2017.csv)

```{python}
police_2017 = pd.read_csv('nyc_police_exam_sept_2017.csv')
police_2017.head()
```

The exam mark is in the column named `Adj. FA`, short for "Adjusted Final
Average".

For convenience, we round the exam scores to the nearest integer:

```{python}
police_2017['Adj. FA'] = police_2017['Adj. FA'].round()
```

There are about 13000 marks in this table:

```{python}
len(police_2017)
```


Here is the histogram:

```{python}
police_2017.hist('Adj. FA');
```


Here are the various statistics for the 2017 marks:

```{python}
police_2017['Adj. FA'].describe()
```

We are particularly interested in the median.  As you remember, this is the 50% percentile, that you see in the table above.

```{python}
# Median mark in 2017.
mark_med_2017 = police_2017['Adj. FA'].median()
mark_med_2017
```

Now we look at the sample of 50 exams from 2019 that you marked quickly.

You can download the sample file from [nyc_police_exam_2019_sample.csv]({{
site.baseurl }}/data/nyc_police_exam_2019_sample.csv)

```{python}
police_2019_sample = pd.read_csv('nyc_police_exam_2019_sample.csv')
# Round marks to nearest integer again.
police_2019_sample['Adj. FA'] = police_2019_sample['Adj. FA'].round()
police_2019_sample.head()
```

```{python}
len(police_2019_sample)
```

```{python}
police_2019_sample.hist('Adj. FA');
```

```{python}
police_2019_sample['Adj. FA'].describe()
```

```{python}
# Median mark in 2019 sample.
mark_med_2019_samp = police_2019_sample['Adj. FA'].median()
mark_med_2019_samp
```

The median here is 92.  That seems a bit higher than the 2017 median --- but
have I been deceived by the sample?  Was I just unlucky?   How confident can I
be that the median from the full results will be 91, or 92, or 93, rather than
the 90 of the previous year?


We now enter the territory of *confidence intervals*.

The sample median is 92, but how close is that median likely to be to the
eventual median, once I have all 13000 or so results for 2019?  How *confident*
can I be in this median of around 92?
