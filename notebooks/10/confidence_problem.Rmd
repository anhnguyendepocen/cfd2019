---
jupyter:
  jupytext:
    split_at_heading: true
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

Imagine for a moment that you are the person who supervises recruitment for the
New York City police department.

Anyone who wants to be a police officer in New York City, has take a [written
exam](https://www1.nyc.gov/site/nypd/careers/police-officers/po-exam.page). The
city puts on this exam every year or so.

There was a written exam in early 2017; over 10000 people took this exam.

Now it is 2019.   This new iteration of the written exam has just finished, and
you know that about 13000 people took the exam, but the results are not out
yet.  Of course you do have the results from 2017.
You are particularly interested in this year's results, because you are worried
that candidates are starting to find the exam too easy, especially with all the
exam preparation materials that candidates can find and buy.

In order to plan for the year ahead, you need to know if the results are
holding steady.   But, as things stand, you won't get the full results for 2019
for another month.

To help your decision-making, you very much want to get an idea of how good the
results are this year.  You decide to take a random sample of 50
from all the exam papers from this year (2019).  You get them marked quickly.
But - how much information will this sample give you about the eventual results
for 2019?

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
plt.style.use('fivethirtyeight')
```

Here are the
[actual](https://github.com/matthew-brett/datasets/tree/22203c1/nyc_civil_list)
examination results from the big 2017 police written exam.


You can download the file from [nyc_police_exam_sept_2017.csv]({{ site.baseurl
}}/data/nyc_police_exam_sept_2017.csv)

```{python}
police_2017 = pd.read_csv('nyc_police_exam_sept_2017.csv')
police_2017.head()
```

The exam mark is in the column named `Adj. FA`, short for "Adjusted Final
Average".

```{python}
marks_2017 = police_2017['Adj. FA']
```

There are about 10000 marks in this table:

```{python}
len(marks_2017)
```


Here is the histogram, where the histogram has 100 bins to show more detail of
the distribution.

```{python}
marks_2017.hist(bins=100);
```

Notice that this isn't a normal distribution; the marks are discrete rather than continuous, they fall into a number of bins across the range of values.


Here are the various statistics for the 2017 marks:

```{python}
marks_2017.describe()
```

We are particularly interested in the mean.

```{python}
# Mean mark in 2017.
mean_2017 = marks_2017.mean()
mean_2017
```

Now we look at the sample of 50 exams from 2019 that you marked quickly.

You can download the sample file from [nyc_police_exam_2019_sample.csv]({{
site.baseurl }}/data/nyc_police_exam_2019_sample.csv)

```{python}
police_2019_sample = pd.read_csv('nyc_police_exam_2019_sample.csv')
marks_2019_sample.head()
```

```{python}
len(marks_2019_sample)
```

```{python}
marks_2019_sample.hist();
```

```{python}
marks_2019_sample.describe()
```

```{python}
# Mean mark in 2019 sample.
mean_2019_samp = marks_2019_sample.mean()
mean_2019_samp
```

The mean here is around 91.23.  That seems a bit higher than the 2017 mean ---
but have I been deceived by the sample?  Was I just unlucky?   How confident
can I be that the mean from the full results will be around 91, or 90, or 91.5,
rather than around 89.16, as it was in the previous year?


We now enter the territory of *confidence intervals*.

The sample mean is 91.23, but how close is that mean likely to be to the
eventual mean, once I have all 13000 or so results for 2019?  How *confident*
can I be in this mean of around 91.2?
